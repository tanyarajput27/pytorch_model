{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNp1fNutberSrPKFiKjHmdw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PalakDograCSE-AI2004/CVDL_Summer_Internship/blob/main/HAR_case_study2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here we are doing 2nd case study with defining ie writing whole alexnet pre trained cnn model architecture ourself"
      ],
      "metadata": {
        "id": "A5v8I3A4OHM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPTHEQ7NLAWx",
        "outputId": "d722947f-8d8e-4db4-a9d7-4b7c3009644d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "401 - Unauthorized\n"
          ]
        }
      ],
      "source": [
        "#import os\n",
        "os.environ[\"KAGGLE_USERNAME\"]=\"priyamalik630\"\n",
        "os.environ[\"KAGGLE_KEY\"]=\"3e7ac7acd3510bbb936768912ac3dffd\"\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip human-action-recognition-har-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqpfoSjfLLe_",
        "outputId": "e1581669-aa7b-4f45-a7f7-234d14bfda0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open human-action-recognition-har-dataset.zip, human-action-recognition-har-dataset.zip.zip or human-action-recognition-har-dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PIL\n",
        "# opencv"
      ],
      "metadata": {
        "id": "KxsFyzcfLUyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torch.utils import data\n",
        "import torchvision.datasets as datasets"
      ],
      "metadata": {
        "id": "2epPUXtELcRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "r1NcOLNZLcOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explore Dataset**"
      ],
      "metadata": {
        "id": "SiU3XkheLy1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"Human Action Recognition/train\"\n",
        "test_path = \"Human Action Recognition/test\""
      ],
      "metadata": {
        "id": "nl9WMO9ILcLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_img = train_path + \"/\" + \"Image_5.jpg\""
      ],
      "metadata": {
        "id": "kc60X9mCLcI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(random_img)"
      ],
      "metadata": {
        "id": "qZeJBwJPLcF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(img)\n"
      ],
      "metadata": {
        "id": "THSenB-8LcDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "AMV_MKGpLcAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OQX52QYTLb93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"Human Action Recognition/Training_set.csv\")\n"
      ],
      "metadata": {
        "id": "qycHvDxlLb6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "MEyfvV2YLb4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.value_counts(df['label'])\n"
      ],
      "metadata": {
        "id": "WTHW2fS4Lb1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = pd.value_counts(df['label']).index"
      ],
      "metadata": {
        "id": "JsPd_HmULbyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = np.sort(class_names)\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "eQ2t2_CuLbvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[545]"
      ],
      "metadata": {
        "id": "-VHcwSxZLbsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filenames = df['filename'].values"
      ],
      "metadata": {
        "id": "QQy1F64qLbqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filenames[:10]"
      ],
      "metadata": {
        "id": "rpBx-Cj3LbnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'][0]\n"
      ],
      "metadata": {
        "id": "WYH57SfhLbkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "def load_data(path, df):\n",
        "  images_list = []\n",
        "  labels_list = []\n",
        "  for i in tqdm(range(len(filenames))):\n",
        "    # concat train_path with image name\n",
        "    img_path = path + \"/\" + filenames[i]\n",
        "    # fetch image label from data frame of current image\n",
        "    img_label = df['label'][i]\n",
        "    # read image using opencv\n",
        "    img = cv2.imread(img_path)\n",
        "    # resize image because images might be of different dimensions\n",
        "    # in order to maintain array, we have to resize all the images in same dimension\n",
        "    # img = cv2.resize(img, (150,150))\n",
        "    # img = transform(img)\n",
        "    # img = img / 255.0\n",
        "    # store images one by one in your list\n",
        "    images_list.append(img)\n",
        "    labels_list.append(img_label)\n",
        "\n",
        "  images_arr = np.asarray(images_list)\n",
        "  labels_arr = np.asarray(labels_list)\n",
        "\n",
        "  return images_arr, labels_arr"
      ],
      "metadata": {
        "id": "A5_WsBO9Lbhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df = pd.read_csv(\"Human Action Recognition/Training_set.csv\")\n",
        "# test_df = pd.read_csv(\"Human Action Recognition/Testing_set.csv\")\n",
        "#we will only deal with train data"
      ],
      "metadata": {
        "id": "B0NAL2VVLbf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_df.head()"
      ],
      "metadata": {
        "id": "6ZbC53FVLbcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_labels = load_data(train_path, train_df)"
      ],
      "metadata": {
        "id": "7lw33to4LbZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "id": "D96eS193LbXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_images[1670])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "89UeqZgMLbUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[0]"
      ],
      "metadata": {
        "id": "7K4uxVuyLbRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inherit Dataset class coming from data package\n",
        "class Dataset(data.Dataset):\n",
        "  def __init__(self, images, labels):\n",
        "    self.transforms = transforms\n",
        "    self.images = images\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # loading data - one image at a time\n",
        "    X = self.images[index]\n",
        "    X = cv2.resize(img,(227,227))\n",
        "    y = self.labels[index]\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    X = transform(X)\n",
        "    # X = torch.tensor(X)\n",
        "    # X = torch.cat((X,X,X),0)\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "PVJxtVB0NJ6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(train_labels, return_counts=True)\n"
      ],
      "metadata": {
        "id": "Sowwq00rNJ21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = LabelEncoder()\n",
        "train_labels = label.fit_transform(train_labels)"
      ],
      "metadata": {
        "id": "VVTzJ7JSNJ0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(train_labels, return_counts=True)"
      ],
      "metadata": {
        "id": "5Rkdgip-NJyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 75% - training and 25% - testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.25)\n"
      ],
      "metadata": {
        "id": "I1bhWE9HNJvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "iHYm6Jy8NJst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "id": "AnDdayxdNJpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\"batch_size\":32, \"shuffle\":True}\n",
        "\n",
        "training_set = Dataset(x_train, y_train)\n",
        "training_generator = data.DataLoader(training_set, **params)\n",
        "\n",
        "test_set = Dataset(x_test, y_test)\n",
        "test_generator = data.DataLoader(test_set, **params)\n"
      ],
      "metadata": {
        "id": "zYMopEEiNJnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "# x_train, x_test = x_train / 255.0, x_test / 255.0\n"
      ],
      "metadata": {
        "id": "axZJdocmNcXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class AlexNet(nn.Module):\n",
        "  def __init__(self, num_classes=15):\n",
        "    super().__init__()\n",
        "    self.cnn_blocks = nn.Sequential(\n",
        "        nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        nn.Conv2d(96, 256, kernel_size=3, stride=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        nn.Conv2d(256, 384, kernel_size=3, stride=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(384, 384, kernel_size=3, stride=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(384, 256, kernel_size=3, stride=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    )\n",
        "    self.fcn_blocks = nn.Sequential(\n",
        "        nn.Linear(1024, 4096),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(4096, num_classes),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.cnn_blocks(x)\n",
        "    x = torch.flatten(x,1)\n",
        "    x = self.fcn_blocks(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4_LunTWYNcTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlexNet()\n",
        "\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "oz7gbAX7NcQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  correct_classification = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct_classification / len(y_pred)) * 100\n",
        "  return acc\n"
      ],
      "metadata": {
        "id": "n168GMZyNcN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "hvOs6T02Nvsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(x_train)"
      ],
      "metadata": {
        "id": "fQH5LDNwNvo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# Evaluation metric\n",
        "def accuracy(y_true, y_pred):\n",
        "  # y_true = 1, y_pred = 1\n",
        "  # y_true = 0, y_pred = 0\n",
        "  correct_classification = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct_classification / len(y_pred)) * 100\n",
        "  return acc\n",
        "\n",
        "def train_step(epoch, model, data, loss_fn, optimizer):\n",
        "  train_loss, train_acc = 0,0\n",
        "  model.to(device)\n",
        "\n",
        "  for batch, (X, y) in enumerate(data):\n",
        "    X,y = X.to(device), y.to(device)\n",
        "\n",
        "    # Feedforward - it calls forward method inside Model Class\n",
        "    y_pred = model(X)\n",
        "    # Calculate loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy(y, y_pred.argmax(dim=1))\n",
        "\n",
        "    # Backpropagate\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  train_loss /= len(data)\n",
        "  train_acc /= len(data)\n",
        "  train_acc_history.append(train_acc)\n",
        "  train_loss_history.append(train_loss)\n",
        "  print(f\"Epoch : {epoch} | Train Loss : {train_loss:.3f} |  Train Acc : {train_acc:.3f}\")\n",
        "\n",
        "\n",
        "def test_step(epoch, model, data, loss_fn, optimizer):\n",
        "  test_loss, test_acc = 0,0\n",
        "  model.to(device)\n",
        "  model.to(eval)\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y) in enumerate(data):\n",
        "      X,y = X.to(device), y.to(device)\n",
        "\n",
        "      # Feedforward - it calls forward method inside Model Class\n",
        "      y_pred = model(X)\n",
        "      # Calculate loss\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      test_loss += loss\n",
        "      test_acc += accuracy(y, y_pred.argmax(dim=1))\n",
        "\n",
        "    test_loss /= len(data)\n",
        "    test_acc /= len(data)\n",
        "    print(f\"Epoch : {epoch} | Test Loss : {test_loss:.3f} |  Test Acc : {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "Kl2nTEcrNvmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlexNet().to(device)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "train_acc_history = []\n",
        "train_loss_history = []\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  train_step(epoch, model, training_generator, loss_function, optimizer)\n",
        "  # test_step(epoch, model, test_generator, loss_function, optimizer)"
      ],
      "metadata": {
        "id": "KE4s12mRNvkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AhVt2-bINvhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cuNZlQ3fNvfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m-6GPfYANvb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eC8keEU0NvZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LBP80BQUNvXH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}