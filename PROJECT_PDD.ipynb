{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PalakDograCSE-AI2004/CVDL_Summer_Internship/blob/main/PROJECT_PDD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL4vjQ06uT2Z"
      },
      "outputs": [],
      "source": [
        "# project plant disease detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhGlu_GWu3XW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from sklearn import svm, neighbors, ensemble, tree, naive_bayes\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "#import timm\n",
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6M1vAxGvUkM"
      },
      "outputs": [],
      "source": [
        "zip_file_path =\"drive/MyDrive/archive.zip\"\n",
        "extract_path =\"drive/MyDrive/plantdiseasedetection\"\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGixMr-BwxXL"
      },
      "outputs": [],
      "source": [
        "# 1. Data Augmentation\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=20),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.Resize((224, 224)),  # Resize images to a consistent size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65tMqsYOxaG4"
      },
      "outputs": [],
      "source": [
        "# 2. Load and Preprocess Data\n",
        "\n",
        "data_path = \"drive/MyDrive/plantdiseasedetection\"\n",
        "dataset = ImageFolder(data_path, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geJEfNbJybow"
      },
      "outputs": [],
      "source": [
        "# 3. Splitting the Data\n",
        "\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.15 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=32)\n",
        "test_loader = DataLoader(test_set, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab8A7MwqyfmE",
        "outputId": "f96df881-ef38-411c-ee88-424f3059f972"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 78.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# 4. Feature Extraction (Using CNN Features)\n",
        "model = models.resnet18(pretrained=True)\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove the last FC layer\n",
        "\n",
        "def extract_features(loader):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            outputs = model(inputs)  # Use tensor inputs directly\n",
        "            features.extend(outputs)\n",
        "            labels.extend(targets)\n",
        "    return features, labels\n",
        "\n",
        "train_features, train_labels = extract_features(train_loader)\n",
        "val_features, val_labels = extract_features(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99bDKHtz3bAX"
      },
      "outputs": [],
      "source": [
        "train_features_numpy = torch.stack(train_features).numpy()\n",
        "val_features_numpy = torch.stack(val_features).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up9YcIm23ldr"
      },
      "outputs": [],
      "source": [
        "train_features_flattened = train_features_numpy.reshape(len(train_features_numpy), -1)\n",
        "val_features_flattened = val_features_numpy.reshape(len(val_features_numpy), -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cbno5YKD-ZUO"
      },
      "outputs": [],
      "source": [
        "train_labels_numpy = np.array(train_labels)\n",
        "val_labels_numpy = np.array(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYEuB-a8-dc9"
      },
      "outputs": [],
      "source": [
        "# Defining the parameters grid for GridSearchCV\n",
        "param_grid={'C':[0.1,1,10,100],\n",
        "            'gamma':[0.0001,0.001,0.1,1],\n",
        "            'kernel':['rbf','poly']}\n",
        "\n",
        "# Creating a support vector classifier\n",
        "svc=svm.SVC(probability=True)\n",
        "\n",
        "# Creating a model using GridSearchCV with the parameters grid\n",
        "model=GridSearchCV(svc,param_grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "qak_oXMy-hVB",
        "outputId": "67ed01a5-3a58-4db7-d087-9ec352068941"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(probability=True),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100],\n",
              "                         &#x27;gamma&#x27;: [0.0001, 0.001, 0.1, 1],\n",
              "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(probability=True),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100],\n",
              "                         &#x27;gamma&#x27;: [0.0001, 0.001, 0.1, 1],\n",
              "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;poly&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(estimator=SVC(probability=True),\n",
              "             param_grid={'C': [0.1, 1, 10, 100],\n",
              "                         'gamma': [0.0001, 0.001, 0.1, 1],\n",
              "                         'kernel': ['rbf', 'poly']})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training the model using the training data\n",
        "model.fit(train_features_flattened, train_labels_numpy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzDrMMuP-kxe",
        "outputId": "7f3fe92f-80ca-4a5a-b584-3286a53a42db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model is 99.86910994764398% accurate\n"
          ]
        }
      ],
      "source": [
        "# Testing the model using the testing data\n",
        "y_pred = model.predict(val_features_flattened)\n",
        "\n",
        "# Calculating the accuracy of the model\n",
        "accuracy = accuracy_score(val_labels_numpy, y_pred)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print(f\"The model is {accuracy*100}% accurate\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mlKkOcU7YMSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPrhh3W5bBAu",
        "outputId": "9351b813-aff5-4527-dc39-1e86ddfc291f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The KNN model is 98.56020942408377% accurate\n"
          ]
        }
      ],
      "source": [
        "# Create a KNN classifier\n",
        "knn = KNeighborsClassifier()  # You can adjust the number of neighbors (k)\n",
        "\n",
        "# Train the KNN model on the training data\n",
        "knn.fit(train_features_flattened, train_labels_numpy)\n",
        "\n",
        "# Testing the KNN model using the validation data\n",
        "y_pred_knn = knn.predict(val_features_flattened)\n",
        "\n",
        "# Calculating the accuracy of the KNN model\n",
        "accuracy_knn = accuracy_score(val_labels_numpy, y_pred_knn)\n",
        "\n",
        "# Print the accuracy of the KNN model\n",
        "print(f\"The KNN model is {accuracy_knn*100}% accurate\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYmftb5wY6x7",
        "outputId": "7f9afb53-df31-493f-db80-70364143f8df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Random Forest is 99.08376963350786% accurate\n"
          ]
        }
      ],
      "source": [
        "rf_model = ensemble.RandomForestClassifier()\n",
        "rf_model.fit(train_features_flattened, train_labels_numpy)\n",
        "rf_predictions = rf_model.predict(val_features_flattened)\n",
        "rf_accuracy = accuracy_score(val_labels_numpy, rf_predictions)\n",
        "print(f\"The Random Forest is {rf_accuracy*100}% accurate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLRmNX6M-pEP",
        "outputId": "237fdf27-e15a-4782-bdb8-c9479ca0b105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Decision Tree is 97.12041884816755% accurate\n"
          ]
        }
      ],
      "source": [
        "dt_model = tree.DecisionTreeClassifier()\n",
        "dt_model.fit(train_features_flattened, train_labels_numpy)\n",
        "dt_predictions = dt_model.predict(val_features_flattened)\n",
        "dt_accuracy = accuracy_score(val_labels_numpy, dt_predictions)\n",
        "print(f\"The Decision Tree is {dt_accuracy*100}% accurate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFcTcWKNWNNc",
        "outputId": "137dbfb4-ad97-4cc8-94ef-b4cb1f59caa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Naive Bayes is 92.40837696335078% accurate\n"
          ]
        }
      ],
      "source": [
        "nb_model = naive_bayes.GaussianNB()\n",
        "nb_model.fit(train_features_flattened, train_labels_numpy)\n",
        "nb_predictions = nb_model.predict(val_features_flattened)\n",
        "nb_accuracy = accuracy_score(val_labels_numpy, nb_predictions)\n",
        "print(f\"The Naive Bayes is {nb_accuracy*100}% accurate\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgEYiU2efL6Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'''class ImageClassificationBase(nn.Module):\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))'''\n"
      ],
      "metadata": {
        "id": "7uBPAz5sI34f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUuK4CFaMoyx"
      },
      "outputs": [],
      "source": [
        "#CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD_KaRiGMo_l"
      },
      "outputs": [],
      "source": [
        "# Create a custom dataset class\n",
        "class PlantDiseaseDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Load data from subdirectories\n",
        "        for label in os.listdir(data_dir):\n",
        "            label_dir = os.path.join(data_dir, label)\n",
        "            for image_file in os.listdir(label_dir):\n",
        "                self.images.append(os.path.join(label_dir, image_file))\n",
        "                self.labels.append(label)\n",
        "\n",
        "    def _len_(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def _getitem_(self, idx):\n",
        "        image = Image.open(self.images[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Create dataset and dataloaders\n",
        "dataset = PlantDiseaseDataset(data_dir=data_path, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oab8q_JLM0jt",
        "outputId": "1d5d4eb1-0d4b-410a-fbc8-694d27fa214e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet18(pretrained=True)  # You can use other pre-trained models as well\n",
        "num_classes = 30  # Number of disease classes\n",
        "\n",
        "# Modify the final fully connected layer to match the number of classes\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE6zjtgtM4TJ",
        "outputId": "f5c2af2c-4f25-4f7c-ff4f-84d1f172ded3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.10804966358643599\n",
            "Epoch 2/10, Loss: 0.005282065014268612\n",
            "Epoch 3/10, Loss: 0.026772667040907954\n",
            "Epoch 4/10, Loss: 0.022888493818884723\n",
            "Epoch 5/10, Loss: 0.02167597617309574\n",
            "Epoch 6/10, Loss: 0.003741800924184905\n",
            "Epoch 7/10, Loss: 0.002926481858025909\n",
            "Epoch 8/10, Loss: 0.00014210153567871333\n",
            "Epoch 9/10, Loss: 9.910945185051137e-05\n",
            "Epoch 10/10, Loss: 0.0010572427220308458\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"plant_disease_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdJ1c0D4M8uT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4d3518-6b36-470c-e101-ce845d86403f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 99.73821989528795%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Validation Accuracy: {100 * correct / total}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}